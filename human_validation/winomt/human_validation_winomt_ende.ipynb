{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20a0de76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import itertools\n",
    "import jsonlines\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from tasks.pattern_matching import WinomtPatternMatchingTask\n",
    "from tasks.pattern_matching.winomt_utils.language_predictors.util import WB_GENDER_TYPES, GENDER\n",
    "from tasks.contrastive_conditioning import WinomtContrastiveConditioningTask\n",
    "from translation_models.fairseq_models import load_sota_evaluator\n",
    "from translation_models.testing_models import DictTranslationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "117642b1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "data_path = Path(\".\") / \"data\"\n",
    "winomt_ende_translations_path = data_path / \"aws.de.full.txt\"\n",
    "winomt_ende_annotator1_path = data_path / \"en-de.annotator1.jsonl\"\n",
    "winomt_ende_annotator2_path = data_path / \"en-de.annotator2.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "450685c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load annotations\n",
    "with jsonlines.open(winomt_ende_annotator1_path) as f:\n",
    "  annotations1 = {line[\"Sample ID\"]: line for line in f}\n",
    "with jsonlines.open(winomt_ende_annotator2_path) as f:\n",
    "  annotations2 = {line[\"Sample ID\"]: line for line in f}\n",
    "\n",
    "# Flatten labels\n",
    "for key in annotations1:\n",
    "    annotations1[key][\"label\"] = annotations1[key][\"label\"][0]\n",
    "for key in annotations2:\n",
    "    annotations2[key][\"label\"] = annotations2[key][\"label\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce2043be",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Remove samples that were only partially annotated\n",
    "for key in list(annotations1.keys()):\n",
    "    if key not in annotations2:\n",
    "        del annotations1[key]\n",
    "for key in list(annotations2.keys()):\n",
    "    if key not in annotations1:\n",
    "        del annotations2[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a1dc432",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9525335231992406\n"
     ]
    }
   ],
   "source": [
    "# Inter-annotator agreement before data cleaning\n",
    "keys = list(annotations1.keys())\n",
    "labels1 = [annotations1[key][\"label\"] for key in keys]\n",
    "labels2 = [annotations2[key][\"label\"] for key in keys]\n",
    "kappa = cohen_kappa_score(labels1, labels2)\n",
    "print(kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11e71de8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Clean data\n",
    "for annotations in [annotations1, annotations2]:\n",
    "    for key in keys:\n",
    "        # Treat neutral as correct\n",
    "        if annotations[key][\"label\"] == \"Both / Neutral / Ambiguous\":\n",
    "            annotations[key][\"label\"] = annotations[key][\"Gold Gender\"].title()\n",
    "        # Treat bad as incorrect\n",
    "        if annotations[key][\"label\"] == \"Translation too bad to tell\":\n",
    "            annotations[key][\"label\"] = \"Male\" if annotations[key][\"Gold Gender\"] == \"female\" else \"Female\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2edfe77f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9526963103122044\n"
     ]
    }
   ],
   "source": [
    "# Inter-annotator agreement after data cleaning\n",
    "keys = list(annotations1.keys())\n",
    "labels1 = [annotations1[key][\"label\"] for key in keys]\n",
    "labels2 = [annotations2[key][\"label\"] for key in keys]\n",
    "kappa = cohen_kappa_score(labels1, labels2)\n",
    "print(kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6759d8f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Merge annotations\n",
    "annotations = list(itertools.chain(annotations1.values(), annotations2.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "055e5638",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load translations\n",
    "with open(winomt_ende_translations_path) as f:\n",
    "    translations = {line.split(\" ||| \")[0].strip(): line.split(\" ||| \")[1].strip() for line in f}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf255175",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3888it [00:00, 42008.08it/s]\n",
      "WARNING:root:less than two dets found: Der Vorgesetzter hat den Buchhalter wegen Nichteinhaltung seines Protokolls beredet.\n",
      "WARNING:root:less than two dets found: Der Analyst konnte den Rezeptionisten wegen seines schlechten Berichts nicht beeindrucken.\n",
      "WARNING:root:less than two dets found: Der Vorgesetzter hat den Buchhalter wegen seines schlechten Verhaltens gescheitert.\n",
      "WARNING:root:less than two dets found: Der Vorgesetzte hat den Buchhalter wegen Nichtbeachtung ihres Protokolls beschattet.\n",
      "WARNING:root:less than two dets found: Der Berater wurde befohlen, den CEO zu untersuchen und ging nach Hause.\n",
      "WARNING:root:less than two dets found: Jemand fragte den Rezeptionisten, ob er sich anmelden müsse.\n",
      "WARNING:root:less than two dets found: Jemand wurde an den Spezialisten verwiesen, weil er Kenntnis von seltenen Hautzuständen hatte.\n",
      "WARNING:root:less than two dets found: Jemand wurde an den Spezialisten verwiesen, weil sie Kenntnis von seltenen Hautzuständen hatte.\n",
      "WARNING:root:less than two dets found: Jemand wurde an den Spezialisten verwiesen, weil sie Kenntnis von seltenen Hautzuständen hatten.\n",
      "WARNING:root:less than two dets found: Der Elektriker warnte den Hausbesitzer, nichts selbst zu verdrahten.\n",
      "WARNING:root:less than two dets found: Der Elektriker warnte den Hausbesitzer, nicht zu versuchen, etwas selbst neu zu verdrahten.\n",
      "WARNING:root:less than two dets found: Der Elektriker warnte den Hausbesitzer, nichts selbst zu verdrahten.\n"
     ]
    }
   ],
   "source": [
    "# Run classic (pattern-matching) WinoMT\n",
    "winomt_pattern_matching = WinomtPatternMatchingTask(\n",
    "    tgt_language=\"de\",\n",
    "    skip_neutral_gold=False,\n",
    "    verbose=True,\n",
    ")\n",
    "pattern_matching_evaluated_samples = winomt_pattern_matching.evaluate(DictTranslationModel(translations)).samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9dde6ba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/user/vamvas/.cache/torch/hub/pytorch_fairseq_master\n",
      "Loading codes from /home/user/vamvas/.cache/torch/pytorch_fairseq/0695ef328ddefcb8cbcfabc3196182f59c0e41e0468b10cc0db2ae9c91881fcc.bb1be17de4233e13870bd7d6065bfdb03fca0a51dd0f5d0b7edf5c188eda71f1/bpecodes ...\n",
      "Read 30000 codes from the codes file.\n",
      "100%|████████████████████████████████████████████████████████████| 3888/3888 [02:36<00:00, 24.77it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 3888/3888 [02:28<00:00, 26.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run contrastive conditioning\n",
    "evaluator_model = load_sota_evaluator(\"de\")\n",
    "winomt_contrastive_conditioning = WinomtContrastiveConditioningTask(\n",
    "    evaluator_model=evaluator_model,\n",
    "    skip_neutral_gold=False,\n",
    "    category_wise_weighting=True,\n",
    ")\n",
    "contrastive_conditioning_weighted_evaluated_samples = winomt_contrastive_conditioning.evaluate(DictTranslationModel(translations)).samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ec016fb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create unweighted contrastive conditioning samples\n",
    "contrastive_conditioning_unweighted_evaluated_samples = deepcopy(contrastive_conditioning_weighted_evaluated_samples)\n",
    "for sample in contrastive_conditioning_unweighted_evaluated_samples:\n",
    "    sample.weight = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ceb5f162",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        male      0.962     0.863     0.910     321.0\n",
      "      female      0.607     0.861     0.712      79.0\n",
      "\n",
      "    accuracy                          0.863     400.0\n",
      "   macro avg      0.784     0.862     0.811     400.0\n",
      "weighted avg      0.892     0.863     0.871     400.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        male      0.942     0.969     0.955     321.0\n",
      "      female      0.857     0.759     0.805      79.0\n",
      "\n",
      "    accuracy                          0.927     400.0\n",
      "   macro avg      0.900     0.864     0.880     400.0\n",
      "weighted avg      0.926     0.927     0.926     400.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        male      0.982     0.991     0.987  343015.0\n",
      "      female      0.914     0.842     0.876   38913.0\n",
      "\n",
      "    accuracy                          0.976  381928.0\n",
      "   macro avg      0.948     0.916     0.931  381928.0\n",
      "weighted avg      0.975     0.976     0.975  381928.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "for evaluated_samples in [\n",
    "    pattern_matching_evaluated_samples,\n",
    "    contrastive_conditioning_unweighted_evaluated_samples,\n",
    "    contrastive_conditioning_weighted_evaluated_samples,\n",
    "]:\n",
    "    predicted_labels = []\n",
    "    gold_labels = []\n",
    "    weights = []\n",
    "    for annotation in annotations:\n",
    "        gold_labels.append(WB_GENDER_TYPES[annotation[\"label\"].lower()].value)\n",
    "        sample_index = int(annotation[\"Index\"])\n",
    "        evaluated_sample = evaluated_samples[sample_index]\n",
    "        assert evaluated_sample.sentence == annotation[\"Source Sentence\"]\n",
    "        if hasattr(evaluated_sample, \"predicted_gender\"):\n",
    "            predicted_gender = evaluated_sample.predicted_gender.value\n",
    "            # Convert neutral or unknown to gold in order to treat pattern-matching WinoMT as fairly as possible\n",
    "            if predicted_gender in {GENDER.neutral.value, GENDER.unknown.value}:\n",
    "                predicted_gender = evaluated_sample.gold_gender.value\n",
    "        else:\n",
    "            if evaluated_sample.is_correct:\n",
    "                predicted_gender = WB_GENDER_TYPES[evaluated_sample.gold_gender].value\n",
    "            else:\n",
    "                predicted_gender = int(not WB_GENDER_TYPES[evaluated_sample.gold_gender].value)\n",
    "        predicted_labels.append(predicted_gender)\n",
    "        weights.append(getattr(evaluated_sample, \"weight\", 1))\n",
    "    class_labels = [gender.value for gender in GENDER][:2]\n",
    "    target_names = [gender.name for gender in GENDER][:2]\n",
    "    print(classification_report(\n",
    "        y_true=gold_labels,\n",
    "        y_pred=predicted_labels,\n",
    "        labels=class_labels,\n",
    "        target_names=target_names,\n",
    "        sample_weight=weights,\n",
    "        zero_division=True,\n",
    "        digits=3,\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
